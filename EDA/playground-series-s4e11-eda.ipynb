{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Decide between local or kaggle cloud storage         \n",
    "KAGGLE_ENV = 'kaggle' in os.listdir('/')\n",
    "data_path = '/kaggle/input' if KAGGLE_ENV else '../kaggle/input'\n",
    "    \n",
    "    \n",
    "for dirname, _, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction\n",
    "\n",
    "In this exploratory data analysis (EDA), we aim to gain a deeper understanding of the dataset by performing the following key steps:\n",
    "\n",
    "- Understand the structure of the data: Identify data types, feature distributions, and basic statistics.\n",
    "- Explore patterns and relationships: Examine correlations, feature interactions, and potential trends.\n",
    "- Detect missing values: Identify incomplete data and evaluate possible imputation strategies.\n",
    "- Identify outliers: Locate extreme values that may impact model performance or require transformation.\n",
    "\n",
    "This analysis will provide valuable insights to guide further data preprocessing and modeling decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_original \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/playground-series-s4e11/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_original \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/playground-series-s4e11/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/playground-series-s4e11/sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_original = pd.read_csv(data_path + '/playground-series-s4e11/train.csv')\n",
    "test_original = pd.read_csv(data_path + '/playground-series-s4e11/test.csv')\n",
    "sample_submission = pd.read_csv(data_path + '/playground-series-s4e11/sample_submission.csv')\n",
    "original_data = pd.read_csv(data_path + '/depression-surveydataset-for-analysis/final_depression_dataset_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview(data, target):\n",
    "    # Overview\n",
    "    display(Markdown(\"## Data Overview\"))\n",
    "    \n",
    "    display(Markdown(\"### General Information\"))\n",
    "    display(Markdown(f\"- Number of rows and columns: {data.shape[0]} x {data.shape[1]}\"))\n",
    "    display(Markdown(\"- Column names:\"))\n",
    "    display(list(data.columns))\n",
    "\n",
    "    display(Markdown(\"### Data Types & Missing Values\"))\n",
    "    missing = data.isnull().sum()\n",
    "    dtypes = pd.DataFrame(data.dtypes, columns=[\"Data Type\"])\n",
    "    missing_df = pd.DataFrame(missing, columns=[\"Missing Values\"])\n",
    "    overview_df = dtypes.join(missing_df)\n",
    "    display(overview_df.style.background_gradient(cmap=\"coolwarm\"))\n",
    "\n",
    "    display(Markdown(\"### Classic head of Data\"))\n",
    "    display(data.head().style.set_properties(**{\"background-color\": \"#f5f5f5\"}))\n",
    "\n",
    "    display(Markdown(\"### Statistical Summary (describe)\"))\n",
    "    display(data.describe().T.style.background_gradient(cmap=\"viridis\"))\n",
    "\n",
    "    # Target variable analysis\n",
    "    display(Markdown(f\"## Target Variable: `{target}`\"))\n",
    "    sns.set_style(\"whitegrid\")  \n",
    "    sns.set_palette(\"viridis\")   \n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Absolute frequency barplot\n",
    "    sns.barplot(x=data[target].value_counts().index, \n",
    "                y=data[target].value_counts(), \n",
    "                ax=ax[0])  \n",
    "\n",
    "    ax[0].set_title(\"Absolute Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "    ax[0].set_ylabel(\"Count\")\n",
    "    ax[0].set_xlabel(target)\n",
    "    ax[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.5)  \n",
    "\n",
    "    # Percentage distribution barplot\n",
    "    sns.barplot(x=data[target].value_counts().index, \n",
    "                y=data[target].value_counts(normalize=True), \n",
    "                ax=ax[1])  \n",
    "\n",
    "    ax[1].set_title(\"Percentage Distribution\", fontsize=12, fontweight=\"bold\")\n",
    "    ax[1].set_ylabel(\"Percentage\")\n",
    "    ax[1].set_xlabel(target)\n",
    "    ax[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    for spine in [\"top\", \"right\"]:\n",
    "        ax[0].spines[spine].set_visible(False)\n",
    "        ax[1].spines[spine].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(original_data, 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(train_original, 'Depression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick PreProcessing about some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_fix = original_data.copy()\n",
    "original_data_fix['Depression'] = original_data_fix['Depression'].map({'Yes': 1, 'No': 0})\n",
    "original_data_fix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Point: Concat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat train and the original data set\n",
    "train = train_original.copy()\n",
    "train.drop('id', axis=1, inplace=True) #id is not needed for training\n",
    "train = pd.concat([train, original_data_fix],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just make sure to concat worked,check if the objecte type is the same\n",
    "train.iloc[train_original.shape[0]-5:train_original.shape[0]+5].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_attributes(df, target=None):\n",
    "    \"\"\" Visualizes numeric and categorical features \"\"\"\n",
    "\n",
    "    # Get Numeric & Categorical Features\n",
    "    numeric_features, categorical_features =get_categorical_numerical_features(df)\n",
    "\n",
    "    # Numeric Features\n",
    "    if numeric_features:\n",
    "        display(Markdown(\"## Numeric Feature Attributes\"))\n",
    "        for col in numeric_features:\n",
    "            if col != target:\n",
    "                plot_numeric_feature(df, col, target)\n",
    "    else:\n",
    "        print(\"No numeric features found.\")\n",
    "\n",
    "    # Categorical Features\n",
    "    if categorical_features:\n",
    "        display(Markdown(\"## Categorical Feature Attributes\"))\n",
    "        for col in categorical_features:\n",
    "            if col != target:\n",
    "                if df[col].nunique() > 10:\n",
    "                    df = reduce_categories(df, col, top_n=15)\n",
    "                plot_categorical_feature(df, col, target)\n",
    "    else:\n",
    "        print(\"No categorical features found.\")\n",
    "\n",
    "\n",
    "def plot_numeric_feature(df, col, target):\n",
    "    \"\"\" Plots Histogram, Boxplot, and Violinplot for a numeric feature \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    sns.histplot(df[col], ax=axes[0], kde=True)\n",
    "    axes[0].set_title(f\"Distribution of {col}\", fontweight=\"bold\")\n",
    "\n",
    "    sns.boxplot(x=df[col], ax=axes[1])\n",
    "    axes[1].set_title(f\"Boxplot of {col}\", fontweight=\"bold\")\n",
    "\n",
    "    if target and target in df.columns and df[target].nunique() == 2:\n",
    "        sns.violinplot(x=df[target], y=df[col], ax=axes[2], split=True)\n",
    "    elif target and target in df.columns:\n",
    "        sns.violinplot(x=df[target], y=df[col], ax=axes[2], split=False)\n",
    "    else:\n",
    "        sns.violinplot(y=df[col], ax=axes[2])\n",
    "\n",
    "    axes[2].set_title(f\"Violinplot of {col} by {target}\", fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_feature(df, col, target):\n",
    "    \"\"\" Plots Countplot, Hue-Countplot, and Barplot (if target is numeric) for a categorical feature \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    sns.countplot(x=df[col], ax=axes[0])\n",
    "    axes[0].set_title(f\"Countplot of {col}\", fontweight=\"bold\")\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    if target in df.columns:\n",
    "        sns.countplot(x=df[col], hue=df[target], ax=axes[1])\n",
    "        axes[1].set_title(f\"Countplot of {col} by {target}\", fontweight=\"bold\")\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    if target in df.columns and df[target].dtype in [np.float64, np.int64]:\n",
    "        sns.barplot(x=df[col], y=df[target], ax=axes[2], estimator=np.mean, errorbar='sd')\n",
    "        axes[2].set_title(f\"Mean {target} by {col}\", fontweight=\"bold\")\n",
    "    else:\n",
    "        axes[2].remove()  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def reduce_categories(df, col, top_n):\n",
    "    \"\"\" Shows only the categories with highes numbers, seldoms are shown with \"others\" \"\"\"\n",
    "    top_categories = df[col].value_counts().nlargest(top_n).index\n",
    "    df[col] = df[col].apply(lambda x: x if x in top_categories else 'Other')\n",
    "    return df\n",
    "\n",
    "def get_categorical_numerical_features(df):\n",
    "    # Get Numeric & Categorical Features\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return numeric_features, categorical_features\n",
    "\n",
    "\n",
    "# Beispiel-Aufruf mit train-Dataset:\n",
    "visualize_feature_attributes(train.drop(columns=['Name']), target=\"Depression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Numeric & Categorical Features\n",
    "numeric_features, categorical_features = get_categorical_numerical_features(train)\n",
    "sns.heatmap(train[numeric_features].corr(), annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(df, feature, target):\n",
    "    # Absolute values calculation (number of cases per feature and target)\n",
    "    degree_dep_table = pd.crosstab(df[feature], df[target])\n",
    "\n",
    "    # Check if target has only two categories (e.g., binary classification)\n",
    "    if len(degree_dep_table.columns) == 2:\n",
    "        # Sort rows by the number of cases where target = 1 (depression cases)\n",
    "        degree_dep_table = degree_dep_table.sort_values(by=1, ascending=False)\n",
    "\n",
    "    # Relative values calculation (row-wise normalization to get percentage values)\n",
    "    degree_dep_table_rel = degree_dep_table.div(degree_dep_table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Ensure that the sorting is applied to both tables\n",
    "    degree_dep_table_rel = degree_dep_table_rel.loc[degree_dep_table.index]\n",
    "\n",
    "    # Combined display: Absolute values + percentage values in one cell\n",
    "    combined_table = degree_dep_table.astype(str) + \" (\" + degree_dep_table_rel.round(2).astype(str) + \"%)\"\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(35, 12))\n",
    "    sns.heatmap(degree_dep_table_rel, annot=combined_table, fmt=\"\", cmap=\"coolwarm\")\n",
    "    plt.title(f\"{target} Distribution by {feature} (Sorted by Highest {target} Cases)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(train, 'Profession', 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(train, 'Degree', 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(train, 'Sleep Duration', 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(train,'Dietary Habits', 'Depression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "- Age: Most people are depressed between19-50 is the highest peak. Biggest number is at 19. Data is good distributed.\n",
    "- Academic Pressure, if you are facing a lot of academic pressure, you more depressed.\n",
    "- Work Pressure. If have a high pressure at work .. you are slightly more depressed.\n",
    "- CPGA, it is good distributed there is not a really hint about that to depression.\n",
    "- Job Satisfaction. If you are depressed than you are depressed...\n",
    "- A lot of work/study hours leads to depression\n",
    "- Financial Stress leads to depression\n",
    "- Students have more depression, correlates also to the age\n",
    "- If you work more then 8 Hours\n",
    "- If you live unhealthy,moderate,healthy\n",
    "- If you are the Class 12, Degree! We have also a lot of data from Class 12!\n",
    "- Profession Feature need a trim. A lot of categories are super small.\n",
    "- Have you ever had suicidal thoughts ,it doesn't mean you are straight depressed.\n",
    "\n",
    "Over all is to say that the categorical features needs a trim. A lot of the attributes of the categorical features has less sample datas. My idea was to group them to others.\n",
    "About the numerical features, they just need a standard transform. About the missing data I will take care in a different script.\n",
    "- Outliers: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save CSV Files as Kaggle Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('/kaggle/working/concat_train_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
